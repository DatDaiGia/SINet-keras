{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import (\n",
    "    Conv2D, BatchNormalization, Dense, \n",
    "    ZeroPadding2D, Activation, GlobalAveragePooling2D,\n",
    "    Reshape, Permute, multiply, AveragePooling2D,\n",
    "    UpSampling2D, Concatenate, Add, Lambda\n",
    ")\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input\n",
    "import keras.backend as K\n",
    "from keras.layers import DepthwiseConv2D, PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNEL = 3\n",
    "CLASSES = [\"Background\", \"Person\"]\n",
    "N_CLASSES = 2\n",
    "IMAGE_DATA_FORMAT = K.image_data_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiNet:\n",
    "    def __init__(self, img_height, img_width, img_channel, n_classes, reg=1e-4):\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.img_channel = img_channel\n",
    "        self.n_classes = n_classes\n",
    "        self.reg = reg\n",
    "        self.channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "        self.alpha = 1.0\n",
    "        \n",
    "    def relu6(self, x):\n",
    "        return K.relu(x, max_value=6)\n",
    "    \n",
    "    def _conv_block(self, inputs, filters, alpha, strides=(1,1), kernel=(3,3), block_id=1, padding=\"valid\"):\n",
    "        \"\"\"\"\"\"\n",
    "        filters = int(filters * alpha)\n",
    "        \n",
    "        if padding==\"same\":\n",
    "            x = inputs\n",
    "        else:\n",
    "            x = ZeroPadding2D((1, 1), data_format=IMAGE_DATA_FORMAT, \n",
    "                              name=\"conv_%s_pad\" % block_id)(inputs)        \n",
    "        \n",
    "        x = Conv2D(filters, kernel, data_format=IMAGE_DATA_FORMAT, \n",
    "                   padding=padding, use_bias=False, strides=strides, \n",
    "                   kernel_initializer=\"he_normal\", name=\"conv_%s\" % block_id)(x)\n",
    "        x = BatchNormalization(axis=self.channel_axis, name=\"conv_%s_bn\" % block_id)(x)\n",
    "        x = Activation(\"relu\", name=\"conv_%s_act\" % block_id)(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _pointwise_conv_block(self, inputs, pointwise_conv_filters, alpha, \n",
    "                              strides=(1, 1), block_id=1):\n",
    "        x = Conv2D(pointwise_conv_filters, \n",
    "                   (1, 1),\n",
    "                   data_format=IMAGE_DATA_FORMAT,\n",
    "                   padding=\"same\",\n",
    "                   use_bias=False,\n",
    "                   strides=(1, 1),\n",
    "                   name=\"conv_pw_%s\" % block_id)(inputs)\n",
    "        x = BatchNormalization(axis=self.channel_axis,\n",
    "                               name=\"conv_pw_%s_bn\" % block_id)(x)\n",
    "        x = Activation(self.relu6, name=\"conv_pw_%s_relu\" % block_id)(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def _depthwise_conv_block(self, inputs, pointwise_conv_filters, alpha, \n",
    "                              depth_multiplier=1, strides=(1, 1), block_id=1, \n",
    "                              kernel=(3,3), padding_size=(1, 1)):\n",
    "        \"\"\"\"\"\"\n",
    "        pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n",
    "        \n",
    "        x = ZeroPadding2D(padding_size, \n",
    "                          data_format=IMAGE_DATA_FORMAT,\n",
    "                          name=\"conv_pad_%s\" % block_id)(inputs)\n",
    "        x = DepthwiseConv2D(kernel_size=kernel,\n",
    "                            data_format=IMAGE_DATA_FORMAT,\n",
    "                            depth_multiplier=depth_multiplier,\n",
    "                            strides=strides,\n",
    "                            use_bias=False,\n",
    "                            name=\"conv_dw_%s\" % block_id)(x)\n",
    "        x = BatchNormalization(axis=self.channel_axis,\n",
    "                               name=\"conv_dw_%s_bn\" % block_id)(x)\n",
    "#         x = Activation(\"PReLu\", name=\"conv_dw_%d_Prelu\" % block_id)(x)\n",
    "        x = PReLU(name=\"conv_dw_%s_Prelu\" % block_id)(x)\n",
    "        \n",
    "        x = self._pointwise_conv_block(x, pointwise_conv_filters, self.alpha, block_id=block_id)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _squeeze_excite_block(self, inputs, ratio=16, block_id=1):\n",
    "        \"\"\"\"\"\"\n",
    "        filters = inputs._keras_shape[self.channel_axis]\n",
    "        se_shape = (1, 1, filters) if self.channel_axis == -1 else (filters, 1, 1)\n",
    "        \n",
    "        se = GlobalAveragePooling2D(name=\"squeeze_glo_avg_%s\" % block_id)(inputs)\n",
    "        se = Dense(filters // ratio, activation=\"relu\", \n",
    "                   kernel_initializer=\"he_normal\", \n",
    "                   use_bias=False, name=\"squeeze_squ_%s\" % block_id)(se)\n",
    "        se = Dense(filters, activation=\"relu\", kernel_initializer=\"he_normal\", \n",
    "                   use_bias=False, name=\"squeeze_exci_%s\" % block_id)(se)\n",
    "        se = multiply([inputs, se], name=\"squeeze_scale_%s\" % block_id)\n",
    "        \n",
    "        return se\n",
    "    \n",
    "    def _depthwise_conv_se_block(self, inputs, pointwise_conv_filters, alpha, \n",
    "                                 depth_multiplier=1, strides=(2, 2), block_id=1,\n",
    "                                 kernel=(3,3), ratio=16):\n",
    "        \"\"\"\n",
    "        DS-Conv + SE\n",
    "        \"\"\"\n",
    "        x = self._depthwise_conv_block(inputs, pointwise_conv_filters, alpha, \n",
    "                                       block_id=block_id, strides=strides)\n",
    "        x = self._squeeze_excite_block(x, ratio=ratio, block_id=block_id)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _s2_block(self, inputs, pointwise_conv_filters, alpha, \n",
    "                  depth_multiplier=1, strides=(1, 1), block_id=1,\n",
    "                  kernel=(3,3), pool_size=(1,1), padding_size=(1, 1)):\n",
    "        x = AveragePooling2D(pool_size=pool_size, strides=(2, 2), \n",
    "                             data_format=IMAGE_DATA_FORMAT, padding=\"same\")(inputs)\n",
    "#         print(x._keras_shape)\n",
    "        x = self._depthwise_conv_block(x, pointwise_conv_filters, alpha, \n",
    "                                       block_id=block_id, kernel=kernel, \n",
    "                                       padding_size=padding_size)\n",
    "#         print(x._keras_shape)\n",
    "        x = UpSampling2D(size=(2, 2), interpolation=\"bilinear\", name=\"s2_block_%s\" % block_id)(x)\n",
    "        \n",
    "        x = BatchNormalization(axis=self.channel_axis)(x)\n",
    "        x = Activation(self.relu6)(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _s2_module(self, inputs, pointwise_conv_filters, alpha,\n",
    "                   depth_multiplier=1, strides=(1, 1), block_id=1,\n",
    "                   kernel_conv=(3, 3), kernel_ds_1=(3, 3), \n",
    "                   kernel_ds_2=(3, 3), pad_ds_1=(1, 1), pad_ds_2=(1, 1),\n",
    "                   pool_block_1=(1, 1), pool_block_2=(1, 1)):\n",
    "        \"\"\"\n",
    "        The function to build S2 block\n",
    "        \"\"\"\n",
    "        x = self._conv_block(inputs, pointwise_conv_filters, alpha, \n",
    "                             kernel=(1, 1), block_id=block_id, padding=\"same\")\n",
    "#         print(x._keras_shape)\n",
    "        x1 = self._s2_block(x, pointwise_conv_filters, alpha, depth_multiplier=depth_multiplier,\n",
    "                            strides=strides, kernel=kernel_ds_1, block_id=str(block_id) + \"_1\",\n",
    "                            padding_size=pad_ds_1, pool_size=pool_block_1)\n",
    "    \n",
    "        x2 = self._s2_block(x, pointwise_conv_filters, alpha, depth_multiplier=depth_multiplier,\n",
    "                            strides=strides, kernel=kernel_ds_2, block_id=str(block_id) + \"_2\", \n",
    "                            padding_size=pad_ds_2, pool_size=pool_block_2)\n",
    "        \n",
    "        x = Concatenate(axis=self.channel_axis)([x1, x2])\n",
    "        x = Add()([inputs, x])\n",
    "        x = BatchNormalization(axis=self.channel_axis)(x)\n",
    "        x = PReLU()(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def build_encoder(self, mean_substraction=[117, 117, 117]):\n",
    "        \"\"\"\n",
    "        Build encoder function\n",
    "        \"\"\"\n",
    "        \n",
    "        input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL)\n",
    "        \n",
    "        if IMAGE_DATA_FORMAT == \"channels_first\":\n",
    "            input_shape = (IMG_CHANNEL, IMG_HEIGHT, IMG_WIDTH)\n",
    "            \n",
    "        inputs = Input(shape=input_shape)\n",
    "        \n",
    "        x = Lambda(lambda z: z[...,::-1], output_shape=input_shape, \n",
    "                   name=\"swap_color_channel\")(inputs)\n",
    "        \n",
    "        if mean_substraction:\n",
    "            x = Lambda(lambda z: z - np.array(mean_substraction),\n",
    "                       output_shape=input_shape,\n",
    "                       name=\"mean_substraction_inputs\")(x)\n",
    "            \n",
    "        x1 = self._conv_block(x, 12, self.alpha, strides=(2, 2), block_id=1)\n",
    "        x2 = self._depthwise_conv_se_block(x1, 16, self.alpha, block_id=2)\n",
    "        x3 = self._depthwise_conv_se_block(x2, 48, self.alpha, block_id=3, strides=(1, 1))\n",
    "        x4 = self._s2_module(x3, 24, self.alpha, block_id=4, kernel_ds_2=(5, 5), pad_ds_2=(2, 2))\n",
    "        x5 = self._s2_module(x4, 24, self.alpha, block_id=5)\n",
    "        \n",
    "        x6 = Concatenate(axis=self.channel_axis, name=\"concat_2_5\")([x2, x5])\n",
    "        \n",
    "        x7 = self._depthwise_conv_se_block(x6, 48, self.alpha, block_id=6)\n",
    "        x8 = self._depthwise_conv_se_block(x7, 96, self.alpha, block_id=7, strides=(1, 1))\n",
    "        x9 = self._s2_module(x8, 48, self.alpha, block_id=8, kernel_ds_2=(5, 5), pad_ds_2=(2, 2))\n",
    "        x10 = self._s2_module(x9, 48, self.alpha, block_id=9)\n",
    "        x11 = self._s2_module(x10, 48, self.alpha, block_id=10, \n",
    "                              kernel_ds_1=(5, 5), pad_ds_1=(2, 2),\n",
    "                              kernel_ds_2=(3, 3), pool_block_2=(2, 2))\n",
    "        x12 = self._s2_module(x11, 48, self.alpha, block_id=11,\n",
    "                              kernel_ds_1=(5, 5), pad_ds_1=(2, 2),\n",
    "                              kernel_ds_2=(3, 3), pool_block_2=(4, 4))\n",
    "        x13 = self._s2_module(x12, 48, self.alpha, block_id=12)\n",
    "        x14 = self._s2_module(x13, 48, self.alpha, block_id=13,\n",
    "                              kernel_ds_1=(5, 5), pad_ds_1=(2, 2),\n",
    "                              kernel_ds_2=(5, 5), pad_ds_2=(2, 2))\n",
    "        x15 = self._s2_module(x14, 48, self.alpha, block_id=14,\n",
    "                              kernel_ds_1=(3, 3), pool_block_1=(2, 2),\n",
    "                              kernel_ds_2=(3, 3), pool_block_2=(4, 4))\n",
    "        x16 = self._s2_module(x15, 48, self.alpha, block_id=15,\n",
    "                              kernel_ds_1=(3, 3), pool_block_1=(1, 1),\n",
    "                              kernel_ds_2=(5, 5), pad_ds_2=(2, 2), pool_block_2=(2, 2))\n",
    "        x17 = Concatenate(axis=self.channel_axis, name=\"concat_16_7\")([x16, x7])\n",
    "        \n",
    "        x = self._pointwise_conv_block(x17, N_CLASSES, self.alpha, block_id=16)\n",
    "        \n",
    "#         x = Reshape((-1, self.n_classes))(x)\n",
    "        \n",
    "#         x = Activation(\"softmax\")(x)\n",
    "        \n",
    "#         model = Model(inputs=inputs, outputs=x)\n",
    "        \n",
    "        return inputs, x, x1, x2\n",
    "    \n",
    "    def build_decoder(self):\n",
    "        inputs, x, x1, x2 = self.build_encoder()\n",
    "        \n",
    "        x = UpSampling2D((2, 2), data_format=IMAGE_DATA_FORMAT, \n",
    "                         interpolation=\"bilinear\")(x)\n",
    "        x_ac = Activation(\"softmax\")(x)\n",
    "        x_blocking = Lambda(lambda x: 1 - x, name=\"information_blocking_decoder\")(x_ac)\n",
    "        \n",
    "        x2_pws = self._pointwise_conv_block(x2, self.n_classes, self.alpha, block_id=17)\n",
    "        \n",
    "        x_mul = Multiply()([x2_pws, x_blocking])\n",
    "        x = Add()([x_mul, x])\n",
    "        x = UpSampling2D((2, 2), interpolation=\"bilinear\")(x)\n",
    "        x = self._conv_block(x, self.n_classes, self.alpha, kernel=(1, 1), padding=\"same\", block_id=18)\n",
    "        x = UpSampling2D((2, 2), interpolation=\"bilinear\")(x)\n",
    "        x = Reshape((-1, self.n_classes))(x)\n",
    "        x = Activation(\"softmax\")(x)\n",
    "        \n",
    "        model = Model(inputs=inputs, outputs=x)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinet = SiNet(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = sinet.build_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "swap_color_channel (Lambda)     (None, 224, 224, 3)  0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mean_substraction_inputs (Lambd (None, 224, 224, 3)  0           swap_color_channel[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_pad (ZeroPadding2D)      (None, 226, 226, 3)  0           mean_substraction_inputs[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 112, 112, 12) 324         conv_1_pad[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_bn (BatchNormalization)  (None, 112, 112, 12) 48          conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_act (Activation)         (None, 112, 112, 12) 0           conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)      (None, 114, 114, 12) 0           conv_1_act[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)     (None, 56, 56, 12)   108         conv_pad_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormalizatio (None, 56, 56, 12)   48          conv_dw_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_2_Prelu (PReLU)         (None, 56, 56, 12)   37632       conv_dw_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_2 (Conv2D)              (None, 56, 56, 16)   192         conv_dw_2_Prelu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormalizatio (None, 56, 56, 16)   64          conv_pw_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_2_relu (Activation)     (None, 56, 56, 16)   0           conv_pw_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_glo_avg_2 (GlobalAverag (None, 16)           0           conv_pw_2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_squ_2 (Dense)           (None, 1)            16          squeeze_glo_avg_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_exci_2 (Dense)          (None, 16)           16          squeeze_squ_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_scale_2 (Multiply)      (None, 56, 56, 16)   0           conv_pw_2_relu[0][0]             \n",
      "                                                                 squeeze_exci_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_3 (ZeroPadding2D)      (None, 58, 58, 16)   0           squeeze_scale_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)     (None, 56, 56, 16)   144         conv_pad_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormalizatio (None, 56, 56, 16)   64          conv_dw_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_3_Prelu (PReLU)         (None, 56, 56, 16)   50176       conv_dw_3_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_3 (Conv2D)              (None, 56, 56, 48)   768         conv_dw_3_Prelu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormalizatio (None, 56, 56, 48)   192         conv_pw_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_3_relu (Activation)     (None, 56, 56, 48)   0           conv_pw_3_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_glo_avg_3 (GlobalAverag (None, 48)           0           conv_pw_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_squ_3 (Dense)           (None, 3)            144         squeeze_glo_avg_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_exci_3 (Dense)          (None, 48)           144         squeeze_squ_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_scale_3 (Multiply)      (None, 56, 56, 48)   0           conv_pw_3_relu[0][0]             \n",
      "                                                                 squeeze_exci_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 56, 56, 24)   1152        squeeze_scale_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_4_bn (BatchNormalization)  (None, 56, 56, 24)   96          conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4_act (Activation)         (None, 56, 56, 24)   0           conv_4_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_181 (AverageP (None, 28, 28, 24)   0           conv_4_act[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_182 (AverageP (None, 28, 28, 24)   0           conv_4_act[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_4_1 (ZeroPadding2D)    (None, 30, 30, 24)   0           average_pooling2d_181[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_4_2 (ZeroPadding2D)    (None, 32, 32, 24)   0           average_pooling2d_182[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_4_1 (DepthwiseConv2D)   (None, 28, 28, 24)   216         conv_pad_4_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_4_2 (DepthwiseConv2D)   (None, 28, 28, 24)   600         conv_pad_4_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_4_1_bn (BatchNormalizat (None, 28, 28, 24)   96          conv_dw_4_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_4_2_bn (BatchNormalizat (None, 28, 28, 24)   96          conv_dw_4_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_4_1_Prelu (PReLU)       (None, 28, 28, 24)   18816       conv_dw_4_1_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_4_2_Prelu (PReLU)       (None, 28, 28, 24)   18816       conv_dw_4_2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_4_1 (Conv2D)            (None, 28, 28, 24)   576         conv_dw_4_1_Prelu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_4_2 (Conv2D)            (None, 28, 28, 24)   576         conv_dw_4_2_Prelu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_4_1_bn (BatchNormalizat (None, 28, 28, 24)   96          conv_pw_4_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_4_2_bn (BatchNormalizat (None, 28, 28, 24)   96          conv_pw_4_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_4_1_relu (Activation)   (None, 28, 28, 24)   0           conv_pw_4_1_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_4_2_relu (Activation)   (None, 28, 28, 24)   0           conv_pw_4_2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_4_1 (UpSampling2D)     (None, 56, 56, 24)   0           conv_pw_4_1_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_4_2 (UpSampling2D)     (None, 56, 56, 24)   0           conv_pw_4_2_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 56, 56, 24)   96          s2_block_4_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 56, 56, 24)   96          s2_block_4_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 56, 56, 24)   0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 56, 56, 24)   0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 56, 56, 48)   0           activation_187[0][0]             \n",
      "                                                                 activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 56, 56, 48)   0           squeeze_scale_3[0][0]            \n",
      "                                                                 concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 56, 56, 48)   192         add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_91 (PReLU)              (None, 56, 56, 48)   150528      batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 56, 56, 24)   1152        p_re_lu_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_5_bn (BatchNormalization)  (None, 56, 56, 24)   96          conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5_act (Activation)         (None, 56, 56, 24)   0           conv_5_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_183 (AverageP (None, 28, 28, 24)   0           conv_5_act[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_184 (AverageP (None, 28, 28, 24)   0           conv_5_act[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_5_1 (ZeroPadding2D)    (None, 30, 30, 24)   0           average_pooling2d_183[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_5_2 (ZeroPadding2D)    (None, 30, 30, 24)   0           average_pooling2d_184[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_5_1 (DepthwiseConv2D)   (None, 28, 28, 24)   216         conv_pad_5_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_5_2 (DepthwiseConv2D)   (None, 28, 28, 24)   216         conv_pad_5_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_5_1_bn (BatchNormalizat (None, 28, 28, 24)   96          conv_dw_5_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_5_2_bn (BatchNormalizat (None, 28, 28, 24)   96          conv_dw_5_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_5_1_Prelu (PReLU)       (None, 28, 28, 24)   18816       conv_dw_5_1_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_5_2_Prelu (PReLU)       (None, 28, 28, 24)   18816       conv_dw_5_2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_5_1 (Conv2D)            (None, 28, 28, 24)   576         conv_dw_5_1_Prelu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_5_2 (Conv2D)            (None, 28, 28, 24)   576         conv_dw_5_2_Prelu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_5_1_bn (BatchNormalizat (None, 28, 28, 24)   96          conv_pw_5_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_5_2_bn (BatchNormalizat (None, 28, 28, 24)   96          conv_pw_5_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_5_1_relu (Activation)   (None, 28, 28, 24)   0           conv_pw_5_1_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_5_2_relu (Activation)   (None, 28, 28, 24)   0           conv_pw_5_2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_5_1 (UpSampling2D)     (None, 56, 56, 24)   0           conv_pw_5_1_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_5_2 (UpSampling2D)     (None, 56, 56, 24)   0           conv_pw_5_2_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 56, 56, 24)   96          s2_block_5_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 56, 56, 24)   96          s2_block_5_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 56, 56, 24)   0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 56, 56, 24)   0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 56, 56, 48)   0           activation_189[0][0]             \n",
      "                                                                 activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 56, 56, 48)   0           p_re_lu_91[0][0]                 \n",
      "                                                                 concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 56, 56, 48)   192         add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_92 (PReLU)              (None, 56, 56, 48)   150528      batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concat_2_5 (Concatenate)        (None, 56, 56, 64)   0           squeeze_scale_2[0][0]            \n",
      "                                                                 p_re_lu_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)      (None, 58, 58, 64)   0           concat_2_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)     (None, 28, 28, 64)   576         conv_pad_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormalizatio (None, 28, 28, 64)   256         conv_dw_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_6_Prelu (PReLU)         (None, 28, 28, 64)   50176       conv_dw_6_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_6 (Conv2D)              (None, 28, 28, 48)   3072        conv_dw_6_Prelu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormalizatio (None, 28, 28, 48)   192         conv_pw_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_6_relu (Activation)     (None, 28, 28, 48)   0           conv_pw_6_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_glo_avg_6 (GlobalAverag (None, 48)           0           conv_pw_6_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_squ_6 (Dense)           (None, 3)            144         squeeze_glo_avg_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_exci_6 (Dense)          (None, 48)           144         squeeze_squ_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_scale_6 (Multiply)      (None, 28, 28, 48)   0           conv_pw_6_relu[0][0]             \n",
      "                                                                 squeeze_exci_6[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_7 (ZeroPadding2D)      (None, 30, 30, 48)   0           squeeze_scale_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)     (None, 28, 28, 48)   432         conv_pad_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormalizatio (None, 28, 28, 48)   192         conv_dw_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_7_Prelu (PReLU)         (None, 28, 28, 48)   37632       conv_dw_7_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_7 (Conv2D)              (None, 28, 28, 96)   4608        conv_dw_7_Prelu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormalizatio (None, 28, 28, 96)   384         conv_pw_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_7_relu (Activation)     (None, 28, 28, 96)   0           conv_pw_7_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_glo_avg_7 (GlobalAverag (None, 96)           0           conv_pw_7_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_squ_7 (Dense)           (None, 6)            576         squeeze_glo_avg_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_exci_7 (Dense)          (None, 96)           576         squeeze_squ_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_scale_7 (Multiply)      (None, 28, 28, 96)   0           conv_pw_7_relu[0][0]             \n",
      "                                                                 squeeze_exci_7[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 28, 28, 48)   4608        squeeze_scale_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_8_bn (BatchNormalization)  (None, 28, 28, 48)   192         conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_8_act (Activation)         (None, 28, 28, 48)   0           conv_8_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_185 (AverageP (None, 14, 14, 48)   0           conv_8_act[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_186 (AverageP (None, 14, 14, 48)   0           conv_8_act[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_8_1 (ZeroPadding2D)    (None, 16, 16, 48)   0           average_pooling2d_185[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_8_2 (ZeroPadding2D)    (None, 18, 18, 48)   0           average_pooling2d_186[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_8_1 (DepthwiseConv2D)   (None, 14, 14, 48)   432         conv_pad_8_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_8_2 (DepthwiseConv2D)   (None, 14, 14, 48)   1200        conv_pad_8_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_8_1_bn (BatchNormalizat (None, 14, 14, 48)   192         conv_dw_8_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_8_2_bn (BatchNormalizat (None, 14, 14, 48)   192         conv_dw_8_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_8_1_Prelu (PReLU)       (None, 14, 14, 48)   9408        conv_dw_8_1_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_8_2_Prelu (PReLU)       (None, 14, 14, 48)   9408        conv_dw_8_2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_8_1 (Conv2D)            (None, 14, 14, 48)   2304        conv_dw_8_1_Prelu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_8_2 (Conv2D)            (None, 14, 14, 48)   2304        conv_dw_8_2_Prelu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_8_1_bn (BatchNormalizat (None, 14, 14, 48)   192         conv_pw_8_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_8_2_bn (BatchNormalizat (None, 14, 14, 48)   192         conv_pw_8_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_8_1_relu (Activation)   (None, 14, 14, 48)   0           conv_pw_8_1_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_8_2_relu (Activation)   (None, 14, 14, 48)   0           conv_pw_8_2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_8_1 (UpSampling2D)     (None, 28, 28, 48)   0           conv_pw_8_1_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_8_2 (UpSampling2D)     (None, 28, 28, 48)   0           conv_pw_8_2_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 28, 28, 48)   192         s2_block_8_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 28, 28, 48)   192         s2_block_8_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 28, 28, 48)   0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 28, 28, 48)   0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 28, 28, 96)   0           activation_191[0][0]             \n",
      "                                                                 activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 28, 28, 96)   0           squeeze_scale_7[0][0]            \n",
      "                                                                 concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 28, 28, 96)   384         add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_93 (PReLU)              (None, 28, 28, 96)   75264       batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                 (None, 28, 28, 48)   4608        p_re_lu_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_9_bn (BatchNormalization)  (None, 28, 28, 48)   192         conv_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_9_act (Activation)         (None, 28, 28, 48)   0           conv_9_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_187 (AverageP (None, 14, 14, 48)   0           conv_9_act[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_188 (AverageP (None, 14, 14, 48)   0           conv_9_act[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_9_1 (ZeroPadding2D)    (None, 16, 16, 48)   0           average_pooling2d_187[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_9_2 (ZeroPadding2D)    (None, 16, 16, 48)   0           average_pooling2d_188[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_9_1 (DepthwiseConv2D)   (None, 14, 14, 48)   432         conv_pad_9_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_9_2 (DepthwiseConv2D)   (None, 14, 14, 48)   432         conv_pad_9_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_9_1_bn (BatchNormalizat (None, 14, 14, 48)   192         conv_dw_9_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_9_2_bn (BatchNormalizat (None, 14, 14, 48)   192         conv_dw_9_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_9_1_Prelu (PReLU)       (None, 14, 14, 48)   9408        conv_dw_9_1_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_9_2_Prelu (PReLU)       (None, 14, 14, 48)   9408        conv_dw_9_2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_9_1 (Conv2D)            (None, 14, 14, 48)   2304        conv_dw_9_1_Prelu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_9_2 (Conv2D)            (None, 14, 14, 48)   2304        conv_dw_9_2_Prelu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_9_1_bn (BatchNormalizat (None, 14, 14, 48)   192         conv_pw_9_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_9_2_bn (BatchNormalizat (None, 14, 14, 48)   192         conv_pw_9_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_9_1_relu (Activation)   (None, 14, 14, 48)   0           conv_pw_9_1_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_9_2_relu (Activation)   (None, 14, 14, 48)   0           conv_pw_9_2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_9_1 (UpSampling2D)     (None, 28, 28, 48)   0           conv_pw_9_1_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_9_2 (UpSampling2D)     (None, 28, 28, 48)   0           conv_pw_9_2_relu[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 28, 28, 48)   192         s2_block_9_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 28, 28, 48)   192         s2_block_9_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 28, 28, 48)   0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 28, 28, 48)   0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 28, 28, 96)   0           activation_193[0][0]             \n",
      "                                                                 activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 28, 28, 96)   0           p_re_lu_93[0][0]                 \n",
      "                                                                 concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 28, 28, 96)   384         add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_94 (PReLU)              (None, 28, 28, 96)   75264       batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 28, 28, 48)   4608        p_re_lu_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_10_bn (BatchNormalization) (None, 28, 28, 48)   192         conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_10_act (Activation)        (None, 28, 28, 48)   0           conv_10_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_189 (AverageP (None, 14, 14, 48)   0           conv_10_act[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_190 (AverageP (None, 14, 14, 48)   0           conv_10_act[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_10_1 (ZeroPadding2D)   (None, 18, 18, 48)   0           average_pooling2d_189[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_10_2 (ZeroPadding2D)   (None, 16, 16, 48)   0           average_pooling2d_190[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_10_1 (DepthwiseConv2D)  (None, 14, 14, 48)   1200        conv_pad_10_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_10_2 (DepthwiseConv2D)  (None, 14, 14, 48)   432         conv_pad_10_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_10_1_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_dw_10_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_10_2_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_dw_10_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_10_1_Prelu (PReLU)      (None, 14, 14, 48)   9408        conv_dw_10_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_10_2_Prelu (PReLU)      (None, 14, 14, 48)   9408        conv_dw_10_2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_10_1 (Conv2D)           (None, 14, 14, 48)   2304        conv_dw_10_1_Prelu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_10_2 (Conv2D)           (None, 14, 14, 48)   2304        conv_dw_10_2_Prelu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_10_1_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_pw_10_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_10_2_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_pw_10_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_10_1_relu (Activation)  (None, 14, 14, 48)   0           conv_pw_10_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_10_2_relu (Activation)  (None, 14, 14, 48)   0           conv_pw_10_2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_10_1 (UpSampling2D)    (None, 28, 28, 48)   0           conv_pw_10_1_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_10_2 (UpSampling2D)    (None, 28, 28, 48)   0           conv_pw_10_2_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 28, 28, 48)   192         s2_block_10_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 28, 28, 48)   192         s2_block_10_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 28, 28, 48)   0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 28, 28, 48)   0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 28, 28, 96)   0           activation_195[0][0]             \n",
      "                                                                 activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_97 (Add)                    (None, 28, 28, 96)   0           p_re_lu_94[0][0]                 \n",
      "                                                                 concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 28, 28, 96)   384         add_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_95 (PReLU)              (None, 28, 28, 96)   75264       batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                (None, 28, 28, 48)   4608        p_re_lu_95[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_11_bn (BatchNormalization) (None, 28, 28, 48)   192         conv_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_11_act (Activation)        (None, 28, 28, 48)   0           conv_11_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_191 (AverageP (None, 14, 14, 48)   0           conv_11_act[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_192 (AverageP (None, 14, 14, 48)   0           conv_11_act[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_11_1 (ZeroPadding2D)   (None, 18, 18, 48)   0           average_pooling2d_191[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_11_2 (ZeroPadding2D)   (None, 16, 16, 48)   0           average_pooling2d_192[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_11_1 (DepthwiseConv2D)  (None, 14, 14, 48)   1200        conv_pad_11_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_11_2 (DepthwiseConv2D)  (None, 14, 14, 48)   432         conv_pad_11_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_11_1_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_dw_11_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_11_2_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_dw_11_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_11_1_Prelu (PReLU)      (None, 14, 14, 48)   9408        conv_dw_11_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_11_2_Prelu (PReLU)      (None, 14, 14, 48)   9408        conv_dw_11_2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_11_1 (Conv2D)           (None, 14, 14, 48)   2304        conv_dw_11_1_Prelu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_11_2 (Conv2D)           (None, 14, 14, 48)   2304        conv_dw_11_2_Prelu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_11_1_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_pw_11_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_11_2_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_pw_11_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_11_1_relu (Activation)  (None, 14, 14, 48)   0           conv_pw_11_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_11_2_relu (Activation)  (None, 14, 14, 48)   0           conv_pw_11_2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_11_1 (UpSampling2D)    (None, 28, 28, 48)   0           conv_pw_11_1_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_11_2 (UpSampling2D)    (None, 28, 28, 48)   0           conv_pw_11_2_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 28, 28, 48)   192         s2_block_11_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 28, 28, 48)   192         s2_block_11_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 28, 28, 48)   0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 28, 28, 48)   0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 28, 28, 96)   0           activation_197[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_98 (Add)                    (None, 28, 28, 96)   0           p_re_lu_95[0][0]                 \n",
      "                                                                 concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 28, 28, 96)   384         add_98[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_96 (PReLU)              (None, 28, 28, 96)   75264       batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 28, 28, 48)   4608        p_re_lu_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_12_bn (BatchNormalization) (None, 28, 28, 48)   192         conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_12_act (Activation)        (None, 28, 28, 48)   0           conv_12_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_193 (AverageP (None, 14, 14, 48)   0           conv_12_act[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_194 (AverageP (None, 14, 14, 48)   0           conv_12_act[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_12_1 (ZeroPadding2D)   (None, 16, 16, 48)   0           average_pooling2d_193[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_12_2 (ZeroPadding2D)   (None, 16, 16, 48)   0           average_pooling2d_194[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_12_1 (DepthwiseConv2D)  (None, 14, 14, 48)   432         conv_pad_12_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_12_2 (DepthwiseConv2D)  (None, 14, 14, 48)   432         conv_pad_12_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_12_1_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_dw_12_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_12_2_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_dw_12_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_12_1_Prelu (PReLU)      (None, 14, 14, 48)   9408        conv_dw_12_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_12_2_Prelu (PReLU)      (None, 14, 14, 48)   9408        conv_dw_12_2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_12_1 (Conv2D)           (None, 14, 14, 48)   2304        conv_dw_12_1_Prelu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_12_2 (Conv2D)           (None, 14, 14, 48)   2304        conv_dw_12_2_Prelu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_12_1_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_pw_12_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_12_2_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_pw_12_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_12_1_relu (Activation)  (None, 14, 14, 48)   0           conv_pw_12_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_12_2_relu (Activation)  (None, 14, 14, 48)   0           conv_pw_12_2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_12_1 (UpSampling2D)    (None, 28, 28, 48)   0           conv_pw_12_1_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_12_2 (UpSampling2D)    (None, 28, 28, 48)   0           conv_pw_12_2_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 28, 28, 48)   192         s2_block_12_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 28, 28, 48)   192         s2_block_12_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 28, 28, 48)   0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 28, 28, 48)   0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 28, 28, 96)   0           activation_199[0][0]             \n",
      "                                                                 activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_99 (Add)                    (None, 28, 28, 96)   0           p_re_lu_96[0][0]                 \n",
      "                                                                 concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 28, 28, 96)   384         add_99[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_97 (PReLU)              (None, 28, 28, 96)   75264       batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 28, 28, 48)   4608        p_re_lu_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_13_bn (BatchNormalization) (None, 28, 28, 48)   192         conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_13_act (Activation)        (None, 28, 28, 48)   0           conv_13_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_195 (AverageP (None, 14, 14, 48)   0           conv_13_act[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_196 (AverageP (None, 14, 14, 48)   0           conv_13_act[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_13_1 (ZeroPadding2D)   (None, 18, 18, 48)   0           average_pooling2d_195[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_13_2 (ZeroPadding2D)   (None, 18, 18, 48)   0           average_pooling2d_196[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13_1 (DepthwiseConv2D)  (None, 14, 14, 48)   1200        conv_pad_13_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13_2 (DepthwiseConv2D)  (None, 14, 14, 48)   1200        conv_pad_13_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13_1_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_dw_13_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13_2_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_dw_13_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13_1_Prelu (PReLU)      (None, 14, 14, 48)   9408        conv_dw_13_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13_2_Prelu (PReLU)      (None, 14, 14, 48)   9408        conv_dw_13_2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_13_1 (Conv2D)           (None, 14, 14, 48)   2304        conv_dw_13_1_Prelu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_13_2 (Conv2D)           (None, 14, 14, 48)   2304        conv_dw_13_2_Prelu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_13_1_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_pw_13_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_13_2_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_pw_13_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_13_1_relu (Activation)  (None, 14, 14, 48)   0           conv_pw_13_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_13_2_relu (Activation)  (None, 14, 14, 48)   0           conv_pw_13_2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_13_1 (UpSampling2D)    (None, 28, 28, 48)   0           conv_pw_13_1_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_13_2 (UpSampling2D)    (None, 28, 28, 48)   0           conv_pw_13_2_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 28, 28, 48)   192         s2_block_13_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 28, 28, 48)   192         s2_block_13_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 28, 28, 48)   0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 28, 28, 48)   0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 28, 28, 96)   0           activation_201[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_100 (Add)                   (None, 28, 28, 96)   0           p_re_lu_97[0][0]                 \n",
      "                                                                 concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 28, 28, 96)   384         add_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_98 (PReLU)              (None, 28, 28, 96)   75264       batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                (None, 28, 28, 48)   4608        p_re_lu_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_14_bn (BatchNormalization) (None, 28, 28, 48)   192         conv_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_14_act (Activation)        (None, 28, 28, 48)   0           conv_14_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_197 (AverageP (None, 14, 14, 48)   0           conv_14_act[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_198 (AverageP (None, 14, 14, 48)   0           conv_14_act[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_14_1 (ZeroPadding2D)   (None, 16, 16, 48)   0           average_pooling2d_197[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_14_2 (ZeroPadding2D)   (None, 16, 16, 48)   0           average_pooling2d_198[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_14_1 (DepthwiseConv2D)  (None, 14, 14, 48)   432         conv_pad_14_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_14_2 (DepthwiseConv2D)  (None, 14, 14, 48)   432         conv_pad_14_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_14_1_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_dw_14_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_14_2_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_dw_14_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_14_1_Prelu (PReLU)      (None, 14, 14, 48)   9408        conv_dw_14_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_14_2_Prelu (PReLU)      (None, 14, 14, 48)   9408        conv_dw_14_2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_14_1 (Conv2D)           (None, 14, 14, 48)   2304        conv_dw_14_1_Prelu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_14_2 (Conv2D)           (None, 14, 14, 48)   2304        conv_dw_14_2_Prelu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_14_1_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_pw_14_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_14_2_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_pw_14_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_14_1_relu (Activation)  (None, 14, 14, 48)   0           conv_pw_14_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_14_2_relu (Activation)  (None, 14, 14, 48)   0           conv_pw_14_2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_14_1 (UpSampling2D)    (None, 28, 28, 48)   0           conv_pw_14_1_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_14_2 (UpSampling2D)    (None, 28, 28, 48)   0           conv_pw_14_2_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 28, 28, 48)   192         s2_block_14_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 28, 28, 48)   192         s2_block_14_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 28, 28, 48)   0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 28, 28, 48)   0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 28, 28, 96)   0           activation_203[0][0]             \n",
      "                                                                 activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_101 (Add)                   (None, 28, 28, 96)   0           p_re_lu_98[0][0]                 \n",
      "                                                                 concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 28, 28, 96)   384         add_101[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_99 (PReLU)              (None, 28, 28, 96)   75264       batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                (None, 28, 28, 48)   4608        p_re_lu_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_15_bn (BatchNormalization) (None, 28, 28, 48)   192         conv_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_15_act (Activation)        (None, 28, 28, 48)   0           conv_15_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_199 (AverageP (None, 14, 14, 48)   0           conv_15_act[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_200 (AverageP (None, 14, 14, 48)   0           conv_15_act[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_15_1 (ZeroPadding2D)   (None, 16, 16, 48)   0           average_pooling2d_199[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_15_2 (ZeroPadding2D)   (None, 18, 18, 48)   0           average_pooling2d_200[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_15_1 (DepthwiseConv2D)  (None, 14, 14, 48)   432         conv_pad_15_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_15_2 (DepthwiseConv2D)  (None, 14, 14, 48)   1200        conv_pad_15_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_15_1_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_dw_15_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_15_2_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_dw_15_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_15_1_Prelu (PReLU)      (None, 14, 14, 48)   9408        conv_dw_15_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_15_2_Prelu (PReLU)      (None, 14, 14, 48)   9408        conv_dw_15_2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_15_1 (Conv2D)           (None, 14, 14, 48)   2304        conv_dw_15_1_Prelu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_15_2 (Conv2D)           (None, 14, 14, 48)   2304        conv_dw_15_2_Prelu[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_15_1_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_pw_15_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_15_2_bn (BatchNormaliza (None, 14, 14, 48)   192         conv_pw_15_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_15_1_relu (Activation)  (None, 14, 14, 48)   0           conv_pw_15_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_15_2_relu (Activation)  (None, 14, 14, 48)   0           conv_pw_15_2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_15_1 (UpSampling2D)    (None, 28, 28, 48)   0           conv_pw_15_1_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "s2_block_15_2 (UpSampling2D)    (None, 28, 28, 48)   0           conv_pw_15_2_relu[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 28, 28, 48)   192         s2_block_15_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 28, 28, 48)   192         s2_block_15_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 28, 28, 48)   0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 28, 28, 48)   0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 28, 28, 96)   0           activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_102 (Add)                   (None, 28, 28, 96)   0           p_re_lu_99[0][0]                 \n",
      "                                                                 concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 28, 28, 96)   384         add_102[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_100 (PReLU)             (None, 28, 28, 96)   75264       batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concat_16_7 (Concatenate)       (None, 28, 28, 144)  0           p_re_lu_100[0][0]                \n",
      "                                                                 squeeze_scale_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_16 (Conv2D)             (None, 28, 28, 2)    288         concat_16_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_16_bn (BatchNormalizati (None, 28, 28, 2)    8           conv_pw_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_16_relu (Activation)    (None, 28, 28, 2)    0           conv_pw_16_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_17 (Conv2D)             (None, 56, 56, 2)    32          squeeze_scale_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 56, 56, 2)    0           conv_pw_16_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_17_bn (BatchNormalizati (None, 56, 56, 2)    8           conv_pw_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 56, 56, 2)    0           up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_17_relu (Activation)    (None, 56, 56, 2)    0           conv_pw_17_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "information_blocking_decoder (L (None, 56, 56, 2)    0           activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 56, 56, 2)    0           conv_pw_17_relu[0][0]            \n",
      "                                                                 information_blocking_decoder[0][0\n",
      "__________________________________________________________________________________________________\n",
      "add_103 (Add)                   (None, 56, 56, 2)    0           multiply_3[0][0]                 \n",
      "                                                                 up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 112, 112, 2)  0           add_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_18 (Conv2D)                (None, 112, 112, 2)  4           up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_18_bn (BatchNormalization) (None, 112, 112, 2)  8           conv_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_18_act (Activation)        (None, 112, 112, 2)  0           conv_18_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 224, 224, 2)  0           conv_18_act[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 50176, 2)     0           up_sampling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 50176, 2)     0           reshape_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,425,004\n",
      "Trainable params: 1,416,496\n",
      "Non-trainable params: 8,508\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.txt', '.DS_Store', 'input', 'val.txt', 'target']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"Nukki/baidu_V1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"Nukki/baidu_V1/train.txt\") as f:\n",
    "#     data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.read_csv(\"Nukki/baidu_V1/train.txt\", header=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['501.png', '502.png', '503.png', ..., '5379.png', '5380.png',\n",
       "       '5381.png'], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugmentation:\n",
    "    def __init__(self):\n",
    "        self.IMAGE_AUGMENTATION_SEQUENCE = None\n",
    "        self.IMAGE_AUGMENTATION_NUM_TRIES = 10\n",
    "        self.loaded_augmentation_name = \"\"\n",
    "    \n",
    "        self.augmentation_functions = {\n",
    "            \"aug_all\": _load_augmentation_aug_all,\n",
    "            \"aug_geometric\": _load_augmentation_aug_geometric,\n",
    "            \"aug_non_geometric\": _load_augmentation_aug_non_geometric\n",
    "        }\n",
    "    \n",
    "    def _load_augmentation_aug_geometric():\n",
    "        return iaa.OneOf([\n",
    "            iaa.Sometimes(0.5, iaa.Fliplr()),\n",
    "            iaa.Sometimes(0.5, iaa.Rotate((-45, 45))),\n",
    "            iaa.Sometimes(0.5, iaa.Affine(\n",
    "                scale={\"x\": (0.5, 1.5), \"y\": (0.5, 1.5)},\n",
    "                order=[0, 1],\n",
    "                mode='constant',\n",
    "                cval=(0, 255),\n",
    "            )),\n",
    "            iaa.Sometimes(0.5, iaa.Affine(\n",
    "                translate_percent={\"x\": (-0.25, 0.25), \"y\": (-0.25, 0.25)},\n",
    "                order=[0, 1],\n",
    "                mode='constant',\n",
    "                cval=(0, 255),\n",
    "            )),\n",
    "        ])\n",
    "    \n",
    "    def _load_augmentation_aug_non_geometric():\n",
    "        return iaa.OneOf([\n",
    "            iaa.Sometimes(0.5, iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)),\n",
    "            iaa.Sometimes(0.5, iaa.OneOf([\n",
    "                iaa.GaussianBlur(sigma=(0.0, 3.0)),\n",
    "                iaa.GaussianBlur(sigma=(0.0, 5.0))\n",
    "            ])),\n",
    "            iaa.Sometimes(0.5, iaa.MultiplyAndAddToBrightness(mul=(0.4, 1.7))),\n",
    "            iaa.Sometimes(0.5, iaa.GammaContrast((0.4, 1.7))),\n",
    "            iaa.Sometimes(0.5, iaa.Multiply((0.4, 1.7), per_channel=0.5)),\n",
    "            iaa.Sometimes(0.5, iaa.MultiplyHue((0.4, 1.7))),\n",
    "            iaa.Sometimes(0.5, iaa.MultiplyHueAndSaturation((0.4, 1.7), per_channel=True)),\n",
    "            iaa.Sometimes(0.5, iaa.LinearContrast((0.4, 1.7), per_channel=0.5))\n",
    "        ])\n",
    "    \n",
    "    def _load_augmentation_aug_all():\n",
    "        return iaa.OneOf([\n",
    "            iaa.Sometimes(0.5, _load_augmentation_aug_geometric()),\n",
    "            iaa.Sometimes(0,5, _load_augmentation_aug_non_geometric())\n",
    "        ])\n",
    "    \n",
    "    def _load_aug_by_name(aug_name=\"aug_all\"):\n",
    "        if not len(self.loaded_augmentation_name):\n",
    "            self.loaded_augmentation_name = aug_name\n",
    "            self.IMAGE_AUGMENTATION_SEQUENCE = augmentation_functions[aug_name]\n",
    "            \n",
    "        return self.IMAGE_AUGMENTATION_SEQUENCE        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"Nukki/\"\n",
    "TRAIN_ANNO_FILE1 = \"Nukki/baidu_V1/train.txt\"\n",
    "TRAIN_ANNO_FILE2 = \"Nukki/baidu_V2/train.txt\"\n",
    "VAL_ANNO_FILE1 = \"Nukki/baidu_V1/val.txt\"\n",
    "VAL_ANNO_FILE2 = \"Nukki/baidu_V2/val.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGeneration:\n",
    "    def __init__(self, \n",
    "                 data_dir, \n",
    "                 anno_paths, \n",
    "#                  test_anno,\n",
    "                 img_height=IMG_HEIGHT,\n",
    "                 img_width=IMG_WIDTH,\n",
    "                 img_channel=IMG_CHANNEL,\n",
    "                 batch_size=36,\n",
    "                 n_classes=N_CLASSES,\n",
    "                 augmentation=True,\n",
    "                 task=\"train\"):\n",
    "        \n",
    "        self.data_dir = data_dir\n",
    "        self.anno_paths = anno_paths\n",
    "#         self.test_anno = test_anno\n",
    "        self.batch_size = batch_size\n",
    "        self.task = task\n",
    "        self.current_index = 0\n",
    "#         self.current_test = 0\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.img_channel = img_channel\n",
    "        self.n_classes = n_classes\n",
    "        self.augmentation = augmentation\n",
    "        self.image_paths, self.label_paths = self.load_image_paths()\n",
    "        \n",
    "    def load_image_paths(self):\n",
    "        image_paths = []\n",
    "        label_paths = []\n",
    "        \n",
    "        for anno_path in self.anno_paths:\n",
    "            anno_dir = os.path.dirname(anno_path)\n",
    "            df_file_names = pd.read_csv(anno_path, header=None)\n",
    "            file_names = df_file_names[0].values\n",
    "            \n",
    "            for fn in file_names:\n",
    "                img_train_dir = os.path.join(anno_dir, \"input\")\n",
    "                img_label_dir = os.path.join(anno_dir, \"target\")\n",
    "                img_train_path = os.path.join(img_train_dir, fn)\n",
    "                img_label_path = os.path.join(img_label_dir, fn)\n",
    "        \n",
    "                image_paths.append(img_train_path)\n",
    "                label_paths.append(img_label_path)\n",
    "            \n",
    "        image_paths = np.array(image_paths)\n",
    "        label_paths = np.array(label_paths)\n",
    "\n",
    "        return image_paths, label_paths\n",
    "    \n",
    "    def get_n_examples(self):\n",
    "        return len(self.image_paths)\n",
    "        \n",
    "    def load_image(self, img_path):\n",
    "        image = cv2.imread(img_path)\n",
    "#         image = image[..., ::-1]\n",
    "        return image\n",
    "    \n",
    "    def parse_label(self, seg_image):\n",
    "        label = seg_image\n",
    "        label = label[:, :, 0]\n",
    "        seg = np.zeros((self.img_height, self.img_width, self.n_classes))\n",
    "        \n",
    "        for i in range(self.n_classes):\n",
    "            seg[:, :, i] = (label == i).astype(\"int\")\n",
    "        \n",
    "        seg = np.reshape(seg, (-1, self.n_classes))\n",
    "        \n",
    "        return seg\n",
    "    \n",
    "    def load_batch(self, img_paths, label_paths):\n",
    "        images = []\n",
    "        segs = []\n",
    "        preprocessors = [self.resize, self.mean_substraction]\n",
    "        \n",
    "        for i in range(len(img_paths)):\n",
    "            image = self.load_image(img_paths[i])\n",
    "            image = self.preprocessing(image, preprocessors)\n",
    "            \n",
    "            seg = self.load_image(label_paths[i])\n",
    "            seg = self.preprocessing(seg)\n",
    "            seg = self.parse_label(seg)\n",
    "            \n",
    "            images.append(image)\n",
    "            segs.append(seg)\n",
    "        \n",
    "        return np.array(images), np.array(segs)\n",
    "    \n",
    "    def resize_img(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        p_h, p_w = 0, 0\n",
    "        \n",
    "        if h>w:\n",
    "            image = imutils.resize(width=self.img_width)\n",
    "            p_h = int((image.shape[0] - self.img_height) / 2)\n",
    "        else:\n",
    "            image = imutils.resize(height=self.img_height)\n",
    "            p_w = int((image.shape[1] - self.img_width) / 2)\n",
    "        \n",
    "        image = image[p_w:image.shape[1]-p_w, p_h: image.shape[0]-p_h]\n",
    "        image = cv2.resize(image, (self.img_height, self.img_width))\n",
    "        return image\n",
    "    \n",
    "    def mean_substraction(self, image, mean=[103.94, 116.78, 123.68], image_val=0.017):\n",
    "        image = (image - np.array(mean))*image_val\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def preprocessing(self, image, preprocessors):\n",
    "        for p in preprocessors:\n",
    "            image = p(image)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def load_batch(self):\n",
    "        if self.current_index + self.batch_size >= len(self.image_paths):\n",
    "            self.current_index = 0\n",
    "            self.image_paths, self.label_paths = shuffle(self.image_paths, self.label_paths, random_state=42)\n",
    "            \n",
    "        img_batch_paths = self.image_paths[self.current_index:self.current_index+self.batch_size]\n",
    "        seg_batch_paths = self.label_paths[self.current_index:self.current_index+self.batch_size]\n",
    "        self.current_index += self.batch_size\n",
    "        inputs, segs = self.load_batch(img_batch_paths, seg_batch_paths)\n",
    "        \n",
    "        return inputs, segs\n",
    "    \n",
    "    def generate(self):\n",
    "        while True:\n",
    "            images, labels = self.load_batch()\n",
    "            \n",
    "            yield (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = DataGeneration(DATA_DIR, [TRAIN_ANNO_FILE1, TRAIN_ANNO_FILE2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10160"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen.get_n_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nukki/baidu_V1/target/501.png', 'Nukki/baidu_V1/target/502.png',\n",
       "       'Nukki/baidu_V1/target/503.png', ...,\n",
       "       'Nukki/baidu_V2/target/26852.jpg',\n",
       "       'Nukki/baidu_V2/target/17457.jpg',\n",
       "       'Nukki/baidu_V2/target/16749.jpg'], dtype='<U31')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen.label_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frotensorflow.no_op.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SINetLoss:\n",
    "    def __init__(self, lamda=0.9):\n",
    "        self.lamda = lamda\n",
    "        \n",
    "    def log_loss(self, y_true, y_pred):\n",
    "        loss = -tf.reduce_sum(y_true * tf.log(y_pred), axis=-1)\n",
    "        return loss\n",
    "        \n",
    "    def boundary_loss(self, y_true, y_pred):\n",
    "#         size, n_classes = tf.shape(y_true)[1:]\n",
    "        batch_size = tf.shape(y_true)[0]\n",
    "        _y_true = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            proto_tensor = tf.make_tensor_proto(y_true[i])\n",
    "            _y_true.append(tf.make_ndarray(proto_tensor))\n",
    "            \n",
    "        y_true = _y_true\n",
    "#         kernel = tf.ones((15, 15), dtype=tf.uint8)\n",
    "        dilation = cv2.dilate(y_true, kernel, iterations=1)\n",
    "        erosion = cv2.erode(y_true, kernel, iterations=1)\n",
    "#         y_true = tf.reshape(y_true, (-1, IMG_HEIGHT, IMG_WIDTH, N_CLASSES))\n",
    "#         dilation = tf.nn.dilation2d(y_true, \n",
    "#                                     filter=[224, 224, N_CLASSES], \n",
    "#                                     strides=[1, 1, 1, 1], \n",
    "#                                     rates=[1, 15, 15, 1],\n",
    "#                                     padding=\"SAME\")\n",
    "        \n",
    "#         erosion = tf.nn.erosion2d(y_true, \n",
    "# #                                   filter=[15, 15, N_CLASSES], \n",
    "#                                   strides=[1, 1, 1, 1], \n",
    "#                                   rates=[1, 15, 15, 1])\n",
    "    \n",
    "        boundary = dilation - erosion\n",
    "        assign_indices = tf.count_nonzero(boundary, axis=-1)\n",
    "        \n",
    "        loss = -tf.reduce_sum(y_true[assign_indices] * tf.log(y_pred[assign_indices]), axis=-1)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        batch_size = tf.shape(y_pred)[0]\n",
    "        \n",
    "        self.lamda = tf.constant(self.lamda)\n",
    "        log_loss = tf.to_float(self.log_loss(y_true, y_pred))\n",
    "        boundary_loss = tf.to_float(self.boundary_loss(y_true, y_pred))\n",
    "        loss = log_loss + self.lamda * boundary_loss\n",
    "        loss *= tf.to_float(batch_size)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.nn.dilation2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinet_loss = SINetLoss().compute_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr = 7.5e-3\n",
    "\n",
    "opt = Adam(lr=init_lr, decay=2e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-07,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-e2c30296242a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msinet_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Git/env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[0;32m--> 345\u001b[0;31m                                                 sample_weight, mask)\n\u001b[0m\u001b[1;32m    346\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/env/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \"\"\"\n\u001b[1;32m    427\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-207-94d9df7841a3>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlamda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mlog_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mboundary_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboundary_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlamda\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mboundary_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-207-94d9df7841a3>\u001b[0m in \u001b[0;36mboundary_loss\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0m_y_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mproto_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_tensor_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0m_y_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=opt, loss=sinet_loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
